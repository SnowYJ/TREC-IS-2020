{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traditional machine learning classifier - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  52508\n",
      "test set:  8179\n"
     ]
    }
   ],
   "source": [
    "# load processed dataset.\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"pre-processed data/dataset_aug_priority.csv\", sep=',')\n",
    "testset = pd.read_csv(\"pre-processed data/new_label_testset.csv\", sep=',')\n",
    "\n",
    "dataset = dataset[dataset['priority'] != 'Unknown']\n",
    "testset = testset[testset['priority'] != 'Unknown']\n",
    "print(\"train set: \", len(dataset))\n",
    "print(\"test set: \", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# create vocab according to tf.\n",
    "count_vec = CountVectorizer(ngram_range=(1, 1), max_features=3000)\n",
    "tf = count_vec.fit_transform(dataset['content'].values.astype('U')).toarray()\n",
    "vocab = count_vec.get_feature_names()\n",
    "\n",
    "# train set.\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 1), min_df=1, vocabulary=vocab)\n",
    "tfidf= tfidf_vec.fit_transform(dataset['content'].values.astype('U')).toarray()\n",
    "\n",
    "# test set.\n",
    "tfidf_vec_test = TfidfVectorizer(ngram_range=(1, 1), min_df=1, vocabulary=vocab)\n",
    "tfidf_test = tfidf_vec_test.fit_transform(testset['content'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abasand</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>above</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zambales</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zone</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.309493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ab  abasand  abbott  abc  ability  able  above  abroad  absolute  \\\n",
       "0  0.000000      0.0     0.0  0.0      0.0   0.0    0.0     0.0       0.0   \n",
       "1  0.000000      0.0     0.0  0.0      0.0   0.0    0.0     0.0       0.0   \n",
       "2  0.309493      0.0     0.0  0.0      0.0   0.0    0.0     0.0       0.0   \n",
       "3  0.000000      0.0     0.0  0.0      0.0   0.0    0.0     0.0       0.0   \n",
       "4  0.000000      0.0     0.0  0.0      0.0   0.0    0.0     0.0       0.0   \n",
       "\n",
       "   absolutely  ...  your  yourself  youtube   yr  zambales  zealand  zero  \\\n",
       "0         0.0  ...   0.0       0.0      0.0  0.0       0.0      0.0   0.0   \n",
       "1         0.0  ...   0.0       0.0      0.0  0.0       0.0      0.0   0.0   \n",
       "2         0.0  ...   0.0       0.0      0.0  0.0       0.0      0.0   0.0   \n",
       "3         0.0  ...   0.0       0.0      0.0  0.0       0.0      0.0   0.0   \n",
       "4         0.0  ...   0.0       0.0      0.0  0.0       0.0      0.0   0.0   \n",
       "\n",
       "   zimbabwe  zone  zulu  \n",
       "0       0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tfidf = pd.DataFrame(tfidf, columns=vocab)\n",
    "testset_tfidf = pd.DataFrame(tfidf_test, columns=vocab)\n",
    "\n",
    "testset_tfidf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52508\n",
      "52508\n",
      "8179\n",
      "8179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tr_X = dataset_tfidf\n",
    "tr_y = dataset['priority']\n",
    "te_X = testset_tfidf\n",
    "te_y = testset['priority']\n",
    "\n",
    "tr_X, tr_y = np.array(tr_X), np.array(tr_y)\n",
    "te_X, te_y = np.array(te_X), np.array(te_y)\n",
    "\n",
    "print(len(tr_X))\n",
    "print(len(tr_y))\n",
    "print(len(te_X))\n",
    "print(len(te_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-class classification for 'priority':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y[tr_y == 'Critical'], te_y[te_y == 'Critical'] = 0, 0\n",
    "tr_y[tr_y == 'Low'], te_y[te_y == 'Low'] = 1, 1\n",
    "tr_y[tr_y == 'Medium'], te_y[te_y == 'Medium'] = 2, 2\n",
    "tr_y[tr_y == 'High'], te_y[te_y == 'High'] = 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error: Unknown label type: 'unknown'\n",
    "tr_y=tr_y.astype('int')\n",
    "te_y=te_y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5104536006846803\n",
      "Precision: 0.3320920387771979\n",
      "Recall: 0.6100083806810869\n",
      "F1-Score: 0.3229423704779127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# logistic regression.\n",
    "clf = LogisticRegression(random_state=0, solver='saga', multi_class='auto', max_iter=300).fit(tr_X, tr_y)\n",
    "preds_te = clf.predict(te_X)\n",
    "\n",
    "print('Accuracy:', accuracy_score(te_y,preds_te))\n",
    "print('Precision:', precision_score(te_y,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(te_y,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(te_y,preds_te,average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TREC-IS metric: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE all:  0.04017644775199684\n"
     ]
    }
   ],
   "source": [
    "prob = clf.predict_proba(te_X)\n",
    "score = 0\n",
    "\n",
    "for i in range(len(te_y)):\n",
    "    if te_y[i] == 0: weight = 1\n",
    "    elif te_y[i] == 1: weight = 0.25\n",
    "    elif te_y[i] == 2: weight = 0.5\n",
    "    elif te_y[i] == 3: weight = 0.75\n",
    "    else: weight = 0\n",
    "    \n",
    "    score += (weight - prob[i, te_y[i]] * weight)**2\n",
    "    \n",
    "score /= len(te_y)\n",
    "\n",
    "print(\"RMSE all: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-label classification for 'Categories': one-vs-rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>view shell gregoire</td>\n",
       "      <td>['FirstPartyObservation', 'Location', 'Emergin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where one fire please stay safe</td>\n",
       "      <td>['ThirdPartyObservation', 'MultimediaShare', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab emerge alrt live gregoire prepare evacuate ...</td>\n",
       "      <td>['MovePeople', 'Location', 'Hashtags']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>view timberlea</td>\n",
       "      <td>['MultimediaShare', 'Hashtags']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0                               view shell gregoire    \n",
       "1                   where one fire please stay safe    \n",
       "2  ab emerge alrt live gregoire prepare evacuate ...   \n",
       "3                                    view timberlea    \n",
       "\n",
       "                                          categories  \n",
       "0  ['FirstPartyObservation', 'Location', 'Emergin...  \n",
       "1  ['ThirdPartyObservation', 'MultimediaShare', '...  \n",
       "2             ['MovePeople', 'Location', 'Hashtags']  \n",
       "3                    ['MultimediaShare', 'Hashtags']  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load processed dataset.\n",
    "dataset_cat = pd.read_csv(\"pre-processed data/dataset_aug_cat.csv\")[['content', 'categories']]\n",
    "testset_cat = pd.read_csv(\"pre-processed data/new_label_testset.csv\")[['content', 'categories']]\n",
    "\n",
    "testset_cat[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45606, 25)\n",
      "(8179, 25)\n"
     ]
    }
   ],
   "source": [
    "# convert categories into matrix.\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# convert str to list.\n",
    "cat_tr_list = []\n",
    "cat_te_list = []\n",
    "\n",
    "for i in dataset_cat['categories']:\n",
    "    cat_tr_list.append(ast.literal_eval(i))\n",
    "    \n",
    "for i in testset_cat['categories']:\n",
    "    cat_te_list.append(ast.literal_eval(i))\n",
    "\n",
    "mlb_tr = MultiLabelBinarizer()\n",
    "labels_tr = mlb_tr.fit_transform(cat_tr_list)\n",
    "mlb_te = MultiLabelBinarizer()\n",
    "labels_te = mlb_te.fit_transform(cat_te_list)\n",
    "\n",
    "categories_tr = mlb_tr.classes_\n",
    "categories_te = mlb_te.classes_\n",
    "\n",
    "print(labels_tr.shape)\n",
    "print(labels_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45606, 3000)\n",
      "(8179, 3000)\n"
     ]
    }
   ],
   "source": [
    "# create vocab according to tf.\n",
    "count_vec = CountVectorizer(ngram_range=(1, 1), max_features=3000)\n",
    "tf = count_vec.fit_transform(dataset_cat['content'].values.astype('U')).toarray()\n",
    "vocab = count_vec.get_feature_names()\n",
    "\n",
    "# td.idf\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 1), min_df=1, vocabulary=vocab)\n",
    "\n",
    "# train set.\n",
    "tfidf_tr= tfidf_vec.fit_transform(dataset_cat['content'].values.astype('U')).toarray()\n",
    "\n",
    "# test set.\n",
    "tfidf_te= tfidf_vec.fit_transform(testset_cat['content'].values.astype('U')).toarray()\n",
    "\n",
    "print(tfidf_tr.shape)\n",
    "print(tfidf_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_X size:  (45606, 3000)\n",
      "tr_y size:  (45606, 25)\n",
      "te_X size:  (8179, 3000)\n",
      "te_y size:  (8179, 25)\n"
     ]
    }
   ],
   "source": [
    "# random split into train and test dataset.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_X, te_X, tr_y, te_y = tfidf_tr, tfidf_te, labels_tr, labels_te\n",
    "\n",
    "print(\"tr_X size: \", tr_X.shape)\n",
    "print(\"tr_y size: \", tr_y.shape)\n",
    "print(\"te_X size: \", te_X.shape)\n",
    "print(\"te_y size: \", te_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Advice  F1-score: 0.22666087711680422  Accuracy:  0.7822472184863676\n",
      "Category: CleanUp  F1-score: 0.22448979591836737  Accuracy:  0.9814158210050128\n",
      "Category: ContextualInformation  F1-score: 0.050031269543464665  Accuracy:  0.8142804743856217\n",
      "Category: Discussion  F1-score: 0.13959085439229843  Accuracy:  0.6503240004890574\n",
      "Category: Donations  F1-score: 0.30809399477806787  Accuracy:  0.9675999510942658\n",
      "Category: EmergingThreats  F1-score: 0.23969213853765806  Accuracy:  0.8309084240127155\n",
      "Category: Factoid  F1-score: 0.32144198272624863  Accuracy:  0.7790683457635408\n",
      "Category: FirstPartyObservation  F1-score: 0.14710568242166755  Accuracy:  0.6072869543954028\n",
      "Category: GoodsServices  F1-score: 0.07246376811594202  Accuracy:  0.9843501650568529\n",
      "Category: Hashtags  F1-score: 0.6376294976049904  Accuracy:  0.602274116640176\n",
      "Category: InformationWanted  F1-score: 0.09302325581395347  Accuracy:  0.9475486000733586\n",
      "Category: Irrelevant  F1-score: 0.4218671152228763  Accuracy:  0.5797774789094021\n",
      "Category: Location  F1-score: 0.2762548949804201  Accuracy:  0.7514366059420468\n",
      "Category: MovePeople  F1-score: 0.30399999999999994  Accuracy:  0.9680890084362391\n",
      "Category: MultimediaShare  F1-score: 0.39888553517529607  Accuracy:  0.6834576354077515\n",
      "Category: NewSubEvent  F1-score: 0.0471976401179941  Accuracy:  0.9210172392713045\n",
      "Category: News  F1-score: 0.47333012974531474  Accuracy:  0.7319965765986062\n",
      "Category: Official  F1-score: 0.15437629221226742  Accuracy:  0.849981660349676\n",
      "Category: OriginalEvent  F1-score: 0.19868791002811623  Accuracy:  0.7909279863063944\n",
      "Category: SearchAndRescue  F1-score: 0.099009900990099  Accuracy:  0.9888739454701063\n",
      "Category: Sentiment  F1-score: 0.5610609688708785  Accuracy:  0.7086440885193789\n",
      "Category: ServiceAvailable  F1-score: 0.163265306122449  Accuracy:  0.8897175693850103\n",
      "Category: ThirdPartyObservation  F1-score: 0.1036077705827937  Accuracy:  0.7630517178139137\n",
      "Category: Volunteer  F1-score: 0.14634146341463417  Accuracy:  0.9871622447731997\n",
      "Category: Weather  F1-score: 0.2589771490750816  Accuracy:  0.9167379875290378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "one_vs_rest = OneVsRestClassifier(LogisticRegression(class_weight=\"balanced\", random_state=0, solver='lbfgs', max_iter=200), n_jobs=1)\n",
    "preds_te_arr = np.zeros(te_y.shape) \n",
    "accuracy = 0\n",
    "\n",
    "for i, category in enumerate(categories_tr):\n",
    "    \n",
    "    one_vs_rest.fit(tr_X, tr_y[:, i])\n",
    "    preds_te = one_vs_rest.predict(te_X)\n",
    "    preds_te_arr[:, i] = preds_te\n",
    "    res = accuracy_score(te_y[:, i], preds_te)\n",
    "    print('Category:', category, ' F1-score:', f1_score(te_y[:, i], preds_te), ' Accuracy: ', res)\n",
    "    accuracy+=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy all:  0.8191270326445776\n",
      "F1-Score all:  0.24268340774030736\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy all: ', accuracy/len(categories_tr))\n",
    "print('F1-Score all: ', f1_score(te_y,preds_te_arr,average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
