{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traditional machine learning classifier - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42762\n",
      "42761\n"
     ]
    }
   ],
   "source": [
    "# load processed dataset.\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"pre-processed data/dataset_aug_priority.csv\", sep=',')\n",
    "print(len(dataset))\n",
    "dataset = dataset[dataset['priority'] != 'Unknown']\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# create vocab according to tf.\n",
    "count_vec = CountVectorizer(ngram_range=(1, 1), max_features=3000)\n",
    "tf = count_vec.fit_transform(dataset['content'].values.astype('U')).toarray()\n",
    "vocab = count_vec.get_feature_names()\n",
    "\n",
    "# td.idf\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 1), min_df=1, vocabulary=vocab)\n",
    "tfidf= tfidf_vec.fit_transform(dataset['content'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abasand</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>above</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abundance</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yukon</th>\n",
       "      <th>zambales</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zone</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ab  abasand  abc  ability  able  above  abroad  absolute  absolutely  \\\n",
       "0  0.0      0.0  0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "1  0.0      0.0  0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "2  0.0      0.0  0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "3  0.0      0.0  0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "4  0.0      0.0  0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "\n",
       "   abundance  ...  your  yourself  youtube   yr  yukon  zambales  zero  \\\n",
       "0        0.0  ...   0.0       0.0      0.0  0.0    0.0       0.0   0.0   \n",
       "1        0.0  ...   0.0       0.0      0.0  0.0    0.0       0.0   0.0   \n",
       "2        0.0  ...   0.0       0.0      0.0  0.0    0.0       0.0   0.0   \n",
       "3        0.0  ...   0.0       0.0      0.0  0.0    0.0       0.0   0.0   \n",
       "4        0.0  ...   0.0       0.0      0.0  0.0    0.0       0.0   0.0   \n",
       "\n",
       "   zimbabwe  zone  zulu  \n",
       "0       0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tfidf = pd.DataFrame(tfidf, columns=vocab)\n",
    "\n",
    "dataset_tfidf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34209\n",
      "34209\n",
      "8552\n",
      "8552\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# split into train and test dataset.\n",
    "tr_X = dataset_tfidf.sample(frac=0.8, random_state=2020)\n",
    "tr_y = dataset.sample(frac=0.8, random_state=2020)['priority']\n",
    "te_X = dataset_tfidf[~dataset_tfidf.index.isin(tr_X.index)]\n",
    "te_y = dataset[~dataset_tfidf.index.isin(tr_X.index)]['priority']\n",
    "\n",
    "tr_X, tr_y = np.array(tr_X), np.array(tr_y)\n",
    "te_X, te_y = np.array(te_X), np.array(te_y)\n",
    "\n",
    "print(len(tr_X))\n",
    "print(len(tr_y))\n",
    "print(len(te_X))\n",
    "print(len(te_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-class classification for 'priority':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y[tr_y == 'Critical'], te_y[te_y == 'Critical'] = 0, 0\n",
    "tr_y[tr_y == 'Low'], te_y[te_y == 'Low'] = 1, 1\n",
    "tr_y[tr_y == 'Medium'], te_y[te_y == 'Medium'] = 2, 2\n",
    "tr_y[tr_y == 'High'], te_y[te_y == 'High'] = 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error: Unknown label type: 'unknown'\n",
    "tr_y=tr_y.astype('int')\n",
    "te_y=te_y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7904583723105706\n",
      "Precision: 0.8003093310868893\n",
      "Recall: 0.8113226037861101\n",
      "F1-Score: 0.8048295539715175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# logistic regression.\n",
    "clf = LogisticRegression(random_state=0, solver='saga', multi_class='auto').fit(tr_X, tr_y)\n",
    "preds_te = clf.predict(te_X)\n",
    "\n",
    "print('Accuracy:', accuracy_score(te_y,preds_te))\n",
    "print('Precision:', precision_score(te_y,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(te_y,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(te_y,preds_te,average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-label classification for 'Categories': one-vs-rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>philippine flood worsen death toll hit wake ge...</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>philippine flood fatality hit</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luzon dam release water flood warn up manila p...</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pagasa advisory yellow warning metro manila oc...</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  philippine flood worsen death toll hit wake ge...   \n",
       "1                     philippine flood fatality hit    \n",
       "2  luzon dam release water flood warn up manila p...   \n",
       "3  pagasa advisory yellow warning metro manila oc...   \n",
       "\n",
       "                                     categories  \n",
       "0  ['ThirdPartyObservation', 'Factoid', 'News']  \n",
       "1  ['ThirdPartyObservation', 'Factoid', 'News']  \n",
       "2  ['ThirdPartyObservation', 'Factoid', 'News']  \n",
       "3  ['ThirdPartyObservation', 'Factoid', 'News']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load processed dataset.\n",
    "dataset_cat = pd.read_csv(\"pre-processed data/new_label_dataset.csv\")[['content', 'categories']]\n",
    "\n",
    "dataset_cat[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37293, 25)\n"
     ]
    }
   ],
   "source": [
    "# convert categories into matrix.\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# convert str to list.\n",
    "cat_list = []\n",
    "for i in dataset_cat['categories']:\n",
    "    cat_list.append(ast.literal_eval(i))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(cat_list)\n",
    "categories = mlb.classes_\n",
    "\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37293, 3000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vocab according to tf.\n",
    "count_vec = CountVectorizer(ngram_range=(1, 1), max_features=3000)\n",
    "tf = count_vec.fit_transform(dataset_cat['content'].values.astype('U')).toarray()\n",
    "vocab = count_vec.get_feature_names()\n",
    "\n",
    "# td.idf\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 1), min_df=1, vocabulary=vocab)\n",
    "tfidf= tfidf_vec.fit_transform(dataset_cat['content'].values.astype('U')).toarray()\n",
    "\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_X size:  (26105, 3000)\n",
      "tr_y size:  (26105, 25)\n",
      "te_X size:  (11188, 3000)\n",
      "te_y size:  (11188, 25)\n"
     ]
    }
   ],
   "source": [
    "# random split into train and test dataset.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_X, te_X, tr_y, te_y = train_test_split(tfidf, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"tr_X size: \", tr_X.shape)\n",
    "print(\"tr_y size: \", tr_y.shape)\n",
    "print(\"te_X size: \", te_X.shape)\n",
    "print(\"te_y size: \", te_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Advice  Accuracy: 0.9478012155881301\n",
      "Category: CleanUp  Accuracy: 0.9948158741508759\n",
      "Category: ContextualInformation  Accuracy: 0.9617447264926707\n",
      "Category: Discussion  Accuracy: 0.9254558455488023\n",
      "Category: Donations  Accuracy: 0.9803360743653915\n",
      "Category: EmergingThreats  Accuracy: 0.9528065784769396\n",
      "Category: Factoid  Accuracy: 0.8723632463353593\n",
      "Category: FirstPartyObservation  Accuracy: 0.8800500536288881\n",
      "Category: GoodsServices  Accuracy: 0.9956203074722917\n",
      "Category: Hashtags  Accuracy: 0.7793171254915982\n",
      "Category: InformationWanted  Accuracy: 0.9925813371469432\n",
      "Category: Irrelevant  Accuracy: 0.8096174472649267\n",
      "Category: Location  Accuracy: 0.8934572756524848\n",
      "Category: MovePeople  Accuracy: 0.9915981408652127\n",
      "Category: MultimediaShare  Accuracy: 0.7935287808366106\n",
      "Category: NewSubEvent  Accuracy: 0.9786378262424026\n",
      "Category: News  Accuracy: 0.8069360028602074\n",
      "Category: Official  Accuracy: 0.961834107972828\n",
      "Category: OriginalEvent  Accuracy: 0.9167858419735431\n",
      "Category: SearchAndRescue  Accuracy: 0.994547729710404\n",
      "Category: Sentiment  Accuracy: 0.831515909903468\n",
      "Category: ServiceAvailable  Accuracy: 0.9637111190561316\n",
      "Category: ThirdPartyObservation  Accuracy: 0.8765641759027529\n",
      "Category: Volunteer  Accuracy: 0.9946371111905613\n",
      "Category: Weather  Accuracy: 0.9485162674293887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "one_vs_rest = OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    \n",
    "    one_vs_rest.fit(tr_X, tr_y[:, i])\n",
    "    \n",
    "    preds_te = one_vs_rest.predict(te_X)\n",
    "\n",
    "    print('Category:', category, ' Accuracy:', accuracy_score(te_y[:, i], preds_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
