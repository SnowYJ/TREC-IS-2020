{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-label tweets classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch   \n",
    "from torchtext import data \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import os\n",
    "from torchtext.vocab import Vectors\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"pre-processed data/new_label_dataset.csv\")[['content', 'categories']]\n",
    "\n",
    "# convert string to list.\n",
    "dataset['categories'] = dataset['categories'].apply(lambda x:literal_eval(x))\n",
    "\n",
    "# seperate 'categories' column.\n",
    "cat_list = []\n",
    "for i in dataset['categories']:\n",
    "    cat_list.append(i)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(cat_list)\n",
    "categories = mlb.classes_\n",
    "\n",
    "\n",
    "for i, cat in enumerate(categories):\n",
    "    dataset[cat] = labels[:, i]\n",
    "    \n",
    "dataset.to_csv(\"pre-processed data/new_label_dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Advice' 'CleanUp' 'ContextualInformation' 'Discussion' 'Donations'\n",
      " 'EmergingThreats' 'Factoid' 'FirstPartyObservation' 'GoodsServices'\n",
      " 'Hashtags' 'InformationWanted' 'Irrelevant' 'Location' 'MovePeople'\n",
      " 'MultimediaShare' 'NewSubEvent' 'News' 'Official' 'OriginalEvent'\n",
      " 'SearchAndRescue' 'Sentiment' 'ServiceAvailable' 'ThirdPartyObservation'\n",
      " 'Volunteer' 'Weather']\n",
      "(37293, 25)\n"
     ]
    }
   ],
   "source": [
    "print(categories)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': ['philippine', 'flood', 'worsen', 'death', 'toll', 'hit', 'wake', 'gener'], 'Advice': '0', 'CleanUp': '0', 'ContextualInformation': '0', 'Discussion': '0', 'Donations': '0', 'EmergingThreats': '0', 'Factoid': '1', 'FirstPartyObservation': '0', 'GoodsServices': '0', 'Hashtags': '0', 'InformationWanted': '0', 'Irrelevant': '0', 'Location': '0', 'MovePeople': '0', 'MultimediaShare': '0', 'NewSubEvent': '0', 'News': '1', 'Official': '0', 'OriginalEvent': '0', 'SearchAndRescue': '0', 'Sentiment': '0', 'ServiceAvailable': '0', 'ThirdPartyObservation': '1', 'Volunteer': '0', 'Weather': '0'}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2020)\n",
    "\n",
    "# loading custom dataset\n",
    "TEXT = data.Field(sequential=True, tokenize=lambda x: x.split(), lower=True)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "fields = [(v, LABEL) for v in categories]\n",
    "\n",
    "fields = [(None, None), ('content', TEXT), (None, None)] + fields\n",
    "\n",
    "dataset=data.TabularDataset(path = 'pre-processed data/new_label_dataset_1.csv',format = 'csv',fields = fields,skip_header = True)\n",
    "\n",
    "print(vars(dataset.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 6543\n",
      "Top words:  [('shoot', 3323), ('earthquake', 2530), ('people', 2370), ('philippine', 2132), ('school', 2119)]\n"
     ]
    }
   ],
   "source": [
    "tr_X, te_X = dataset.split(split_ratio=0.8, random_state = random.seed(2020))\n",
    "tr_x, val_x = tr_X.split(split_ratio=0.7, random_state = random.seed(2020))\n",
    "\n",
    "# load downloaded glove word embedding.\n",
    "cache = '.vector_cache'\n",
    "if not os.path.exists(cache): os.mkdir(cache)\n",
    "vectors = Vectors(name='./glove.840B.300d.txt', cache=cache)\n",
    "\n",
    "# create vocab.\n",
    "TEXT.build_vocab(tr_X, min_freq=3, vectors=vectors)\n",
    "\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "print(\"Top words: \", TEXT.vocab.freqs.most_common(5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "# Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((tr_x, val_x), \n",
    "                                                            batch_sizes = (64, 64),\n",
    "                                                            sort_key = lambda x: len(x.content),\n",
    "                                                            sort_within_batch=False,\n",
    "                                                            repeat=False,\n",
    "                                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "            self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x \n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "\n",
    "            #if self.y_vars is None: # we will concatenate y into a single tensor\n",
    "            y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            yield (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iterator, \"content\", list(categories))\n",
    "valid_dl = BatchWrapper(valid_iterator, \"content\", list(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=30, emb_dim=300):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=0.2, bidirectional = True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, 25)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        embed = self.embedding(seq)\n",
    "        hidden, _ = self.lstm(embed)\n",
    "        embed1 = hidden[-1,:,:] # torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        output = self.fc(embed1)\n",
    "        preds = torch.sigmoid(output) # sigmoid must be used before nn.BCEWithLogitsLoss()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Training Loss:  20.931651260874688  | Validation Loss:  7.253626233339309\n",
      "Epoch:  1  Training Loss:  20.263823487525322  | Validation Loss:  7.22932653597423\n",
      "Epoch:  2  Training Loss:  20.148782229022512  | Validation Loss:  7.2226875045469825\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f02434adde2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-be38281eedfa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0membed1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_dim = 30\n",
    "nl = 3\n",
    "\n",
    "model = LSTM(hidden_dim, emb_dim=300)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-8)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# pre-trained Glove.\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tr_loss = 0.0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in train_dl: \n",
    "        opt.zero_grad()\n",
    "        preds = model(x).squeeze()\n",
    "        loss = loss_func(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tr_loss += loss.item() * x.size(0)\n",
    "\n",
    "    tr_loss /= len(train_dl)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on training mode\n",
    "    index = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_dl:\n",
    "            preds = model(x).squeeze()  \n",
    "            acc = torch.abs(preds - y).view(-1)\n",
    "            acc = (1. - acc.sum() / acc.size()[0]) * 100\n",
    "            loss = loss_func(preds, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            index += 1\n",
    "    acc/=index\n",
    "        \n",
    "    val_loss /= len(valid_dl)\n",
    "\n",
    "    print('Epoch: ',epoch,' Training Loss: ',tr_loss,' | Validation Loss: ',val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import hamming_loss\n",
    "# y_pred = [1, 2, 3, 4]\n",
    "# y_true = [2, 2, 3, 4]\n",
    "# print(hamming_loss(y_true, y_pred))\n",
    " \n",
    "#print(hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorial: http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# dataset = {\n",
    "#     \"input\": torch.tensor([[1, 2, 3, 24, 25, 25, 25, 25],\n",
    "#                            [4, 5, 2, 6, 24, 25, 25, 25],\n",
    "#                            [7, 8, 9, 24, 24, 25, 25, 25],\n",
    "#                            [4, 10, 11, 12, 24, 25, 25, 25],\n",
    "#                            [13, 14, 2, 15, 2, 16, 17, 24],\n",
    "#                            [18, 19, 20, 21, 22, 23, 3, 24]], dtype=torch.long).permute(1, 0),\n",
    "#      \"target\": torch.tensor([[1., 0., 1.],\n",
    "#                              [0., 1., 0.],\n",
    "#                              [1., 0., 1.],\n",
    "#                              [0., 1., 0.],\n",
    "#                              [1., 1., 0.],\n",
    "#                              [0., 0., 1.]], dtype=torch.float32),\n",
    "# }\n",
    "\n",
    "# class MltcModel(torch.nn.Module):\n",
    "#     def __init__(self, vocab_size, emb_dim, hid_dim, rnn_num_layers=1):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.embedding = torch.nn.Embedding(vocab_size, emb_dim)\n",
    "#         self.rnn = torch.nn.GRU(emb_dim, hid_dim, bidirectional=True, num_layers=rnn_num_layers)\n",
    "#         self.l1 = torch.nn.Linear(hid_dim * 2, 256) # * rnn_num_layers 512*2 = 1024\n",
    "#         self.l2 = torch.nn.Linear(256, 3)\n",
    "\n",
    "#     def forward(self, samples):\n",
    "        \n",
    "#         # samples word index.\n",
    "#         embedded = self.embedding(samples)\n",
    "\n",
    "#         _, last_hidden = self.rnn(embedded)\n",
    "\n",
    "#         hidden_list = [last_hidden[i, :, :] for i in range(last_hidden.size()[0])] # 512\n",
    "#         encoded = torch.cat(hidden_list, dim=1) # 1024\n",
    "#         encoded = torch.nn.functional.relu(self.l1(encoded)) # 256\n",
    "#         encoded = torch.nn.functional.sigmoid(self.l2(encoded)) # 2\n",
    "#         return encoded\n",
    "\n",
    "# model = MltcModel(26, 256, 512, rnn_num_layers=1)\n",
    "# criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(dataset[\"input\"])\n",
    "#     loss = criterion(output, dataset[\"target\"])\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     with torch.no_grad():\n",
    "#         acc = torch.abs(output - dataset[\"target\"]).view(-1)\n",
    "#         acc = (1. - acc.sum() / acc.size()[0]) * 100\n",
    "#         print(f'Epoch({epoch+1}) loss: {loss.item()}, accuracy: {acc:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
