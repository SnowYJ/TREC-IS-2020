{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pytorch - LSTM introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/pytorch_LSTM_1.png\" width=\"550\">\n",
    "\n",
    "### 1.1 LSTM architecture：\n",
    "> **model = nn.LSTM(input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional)**\n",
    "1. input_size: 每个单词的 embedding or one-hot encoding 的尺寸，例如：glove 300d。\n",
    "2. hidden_size: 隐含层神经元的个数，例如上图的n。\n",
    "3. num_layers: LSTM的层数，例如上图的层数为1。\n",
    "4. bias: default true。\n",
    "5. batch_first: \n",
    "6. dropout: 0-1\n",
    "7. bidirectional: true or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 100])\n",
      "torch.Size([12, 3])\n",
      "torch.Size([12])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "lstm = nn.LSTM(100, 3, 2)  # word embedding size is 300, hidden layer size is 3, two LSTM layer. \n",
    "print(lstm.all_weights[0][0].shape)\n",
    "print(lstm.all_weights[0][1].shape)\n",
    "print(lstm.all_weights[0][2].shape)\n",
    "print(lstm.all_weights[0][3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 LSTM input and output：\n",
    "><img src=\"image/pytorch_LSTM.png\" width=\"500\">\n",
    ">\n",
    ">**output, ($\\text{h}_n$, $\\text{c}_n$) = model(input, ($\\text{h}_0$, $\\text{c}_0$))**\n",
    ">\n",
    ">* input维度：(句子长度, batch_size（一次多少个句子）, input_size（每个单词向量的长度）) 。\n",
    ">* $\\text{h}_0, \\text{c}_0$维度：(num_layers * num_directions, batch, hidden_size)。例如，上图有w+1层，单向，hidden_size为每个LSTM结构内隐含层神经元个数。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. sentence length:  5  word embedding: torch.Size([1, 100])\n",
      "2. input is every word in sentence:  torch.Size([1, 1, 100])\n",
      "3. output size:  torch.Size([1, 1, 3])\n",
      "4. h_1 size:  torch.Size([2, 1, 3])\n",
      "5. c_1 size:  torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = [torch.randn(1, 100) for _ in range(5)] # In a sentence, 5 words, every words' length is 4.\n",
    "\n",
    "hidden = (torch.randn(2*1, 1, 3), torch.randn(2*1, 1, 3)) # h_0, c_0.\n",
    "\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "print(\"1. sentence length: \",len(inputs),\" word embedding:\",inputs[0].shape)\n",
    "print(\"2. input is every word in sentence: \", i.view(1, 1, -1).shape)\n",
    "print(\"3. output size: \", out.shape)\n",
    "print(\"4. h_1 size: \", hidden[0].shape)\n",
    "print(\"5. c_1 size: \", hidden[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 forward pass\n",
    "\n",
    "**module(data) = module.forward(data)**\n",
    "\n",
    "<img src=\"image/forward.png\" width=\"550\">\n",
    "\n",
    "### 1.4 handle input with variable length\n",
    "\n",
    "https://blog.csdn.net/kejizuiqianfang/article/details/100835528\n",
    "\n",
    "* torch.nn.utils.rnn.pad_sequence()：把不等长的tensor数据, 补充成等长的tensor数据.\n",
    "* torch.nn.utils.rnn.pack_padded_sequence()：把等长的tensor根据所输入的参数压缩成实际的数据, 同时数据格式变成PackedSequence。\n",
    "* torch.nn.utils.rnn.pad_packed_sequence()：把上面所压缩成PackedSequence的数据还原成tensor类型, 并补成等长的数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. bi-directional LSTM \n",
    "\n",
    "**There are two labels in dataset. one is for categories (multi-label), another is for priority (multi-class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-processed dataset.\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch   \n",
    "from torchtext import data \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import os\n",
    "from torchtext.vocab import Vectors\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>categories</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>philippine flood worsen death toll hit wake ge...</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>philippine flood fatality hit</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luzon dam release water flood warn up manila p...</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pagasa advisory yellow warning metro manila oc...</td>\n",
       "      <td>['ThirdPartyObservation', 'Factoid', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pagasa advisory green warning metro manila mod...</td>\n",
       "      <td>['ThirdPartyObservation', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  philippine flood worsen death toll hit wake ge...   \n",
       "1                     philippine flood fatality hit    \n",
       "2  luzon dam release water flood warn up manila p...   \n",
       "3  pagasa advisory yellow warning metro manila oc...   \n",
       "4  pagasa advisory green warning metro manila mod...   \n",
       "\n",
       "                                     categories priority  \n",
       "0  ['ThirdPartyObservation', 'Factoid', 'News']      Low  \n",
       "1  ['ThirdPartyObservation', 'Factoid', 'News']      Low  \n",
       "2  ['ThirdPartyObservation', 'Factoid', 'News']      Low  \n",
       "3  ['ThirdPartyObservation', 'Factoid', 'News']      Low  \n",
       "4             ['ThirdPartyObservation', 'News']      Low  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice dataset is extremely unbalanced.\n",
    "dataset = pd.read_csv(\"pre-processed data/new_label_dataset.csv\", usecols=['content', 'categories', 'priority'])\n",
    "\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 \"priority\" classification:\n",
    "\n",
    "\"priority\" involves four categories, including high, medium priority, critical and low. The amount of data labelled \"low\" is far bigger than the sum of others. Therefore, let's use data augmentation for increasing other three kinds of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Easy Data Augmentation (EDA)\n",
    "# data augmentation - synonym replacement [low = 27477, critical = 423, medium prior = 6195, high = 4382]\n",
    "\n",
    "# critical, medium prior and high shoud be increased to 9000.\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "dataset_other = dataset[dataset['priority'] != 'Low']\n",
    "\n",
    "dataset_critical = dataset_other[dataset_other['priority'] == 'Critical'][['priority', 'content']]\n",
    "dataset_medium = dataset_other[dataset_other['priority'] == 'Medium'][['priority', 'content']]\n",
    "dataset_high = dataset_other[dataset_other['priority'] == 'High'][['priority', 'content']]\n",
    "\n",
    "dataset_critical.to_csv(\"dataset_critical.tsv\", sep='\\t', header=False, index=False) # 21\n",
    "dataset_medium.to_csv(\"dataset_medium.tsv\", sep='\\t', header=False, index=False) # 1\n",
    "dataset_high.to_csv(\"dataset_high.tsv\", sep='\\t', header=False, index=False) # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset with label 'critical': 9174\n",
      "dataset with label 'medium': 11812\n",
      "dataset with label 'high': 11589\n",
      "dataset with label 'low':  10187\n"
     ]
    }
   ],
   "source": [
    "# load dataset after data augmentation.\n",
    "\n",
    "dataset_aug_critical = pd.read_csv(\"pre-processed data/data_aug_critical.tsv\", sep='\\t', header=None)\n",
    "dataset_aug_medium = pd.read_csv(\"pre-processed data/data_aug_medium.tsv\", sep='\\t', header=None)\n",
    "dataset_aug_high = pd.read_csv(\"pre-processed data/data_aug_high.tsv\", sep='\\t', header=None)\n",
    "\n",
    "dataset_aug_temp = pd.concat([dataset_aug_critical, dataset_aug_medium])\n",
    "dataset_aug_other = pd.concat([dataset_aug_temp, dataset_aug_high])\n",
    "\n",
    "print(\"dataset with label 'critical':\", len(dataset_aug_critical))\n",
    "print(\"dataset with label 'medium':\", len(dataset_aug_medium))\n",
    "print(\"dataset with label 'high':\", len(dataset_aug_high))\n",
    "print(\"dataset with label 'low': \", len(dataset[dataset['priority'] != 'Low']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Critical</td>\n",
       "      <td>family need rescue road dona petra concepcion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Critical</td>\n",
       "      <td>family need rescue road dona petra concepcion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Critical</td>\n",
       "      <td>cleave family need rescue road dona petra conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Critical</td>\n",
       "      <td>family need rescue road dona petra concepcion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Critical</td>\n",
       "      <td>family need rescue road dona petra concepcion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   priority                                            content\n",
       "0  Critical  family need rescue road dona petra concepcion ...\n",
       "1  Critical  family need rescue road dona petra concepcion ...\n",
       "2  Critical  cleave family need rescue road dona petra conc...\n",
       "3  Critical  family need rescue road dona petra concepcion ...\n",
       "4  Critical  family need rescue road dona petra concepcion ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aug_other.rename(columns = {0: \"priority\", 1: \"content\"}, inplace=True)\n",
    "\n",
    "dataset_aug_other[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dataset:  42762\n"
     ]
    }
   ],
   "source": [
    "# concat them together.\n",
    "dataset_aug_priority = pd.concat([dataset[dataset['priority'] != 'Low'][['priority', 'content']], dataset_aug_other])\n",
    "\n",
    "print(\"new dataset: \", len(dataset_aug_priority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aug_priority.to_csv(\"dataset_aug_priority.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priority': 'Medium', 'content': ['pagasa', 'advisory', 'red', 'warning', 'metro', 'manila', 'heavy', 'intense', 'rain', 'next', 'hr', 'flood', 'low', 'lie', 'area', 'near', 'river']}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2020)\n",
    "\n",
    "# loading custom dataset\n",
    "TEXT = data.Field(tokenize=lambda x: x.split() ,batch_first=True, include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float, batch_first=True)\n",
    "\n",
    "fields = [('priority', LABEL), ('content', TEXT)]\n",
    "\n",
    "dataset=data.TabularDataset(path = 'pre-processed data/dataset_aug_priority.csv',format = 'csv',fields = fields,skip_header = True)\n",
    "\n",
    "print(vars(dataset.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 7994\n",
      "Size of LABEL vocabulary: 4\n",
      "Top words:  [('shoot', 3638), ('flood', 3344), ('school', 3198), ('people', 2834), ('after', 2709)]\n",
      "LABEL vocabulary:  defaultdict(None, {'Medium': 0, 'High': 1, 'Critical': 2, 'Unknown': 3})\n"
     ]
    }
   ],
   "source": [
    "tr_X, te_X = dataset.split(split_ratio=0.8, random_state = random.seed(2020))\n",
    "tr_x, val_x = tr_X.split(split_ratio=0.7, random_state = random.seed(2020))\n",
    "\n",
    "# load downloaded glove word embedding.\n",
    "cache = '.vector_cache'\n",
    "if not os.path.exists(cache): os.mkdir(cache)\n",
    "vectors = Vectors(name='./glove.840B.300d.txt', cache=cache)\n",
    "\n",
    "# create vocab.\n",
    "TEXT.build_vocab(tr_X, min_freq=3, vectors=vectors)\n",
    "LABEL.build_vocab(tr_X)\n",
    "\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "print(\"Top words: \", TEXT.vocab.freqs.most_common(5))  \n",
    "\n",
    "# Word dictionary.\n",
    "print(\"LABEL vocabulary: \", LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_classifier(nn.Module):\n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # bi-directional LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers=n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "\n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "        #activation function\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        # concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "        \n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #retrieve text and no. of words\n",
    "        cont, cont_lengths = batch.content \n",
    "\n",
    "        # forward (convert to 1D tensor) \n",
    "        predictions = model(cont, cont_lengths).squeeze()  \n",
    "\n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, batch.priority.long())  \n",
    "        \n",
    "        # backward\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step() \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()     \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    label_list, preds_list = [], []\n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    # deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            # retrieve text and length\n",
    "            cont, cont_lengths = batch.content \n",
    "\n",
    "            predictions = model(cont, cont_lengths).squeeze()\n",
    "            \n",
    "            # keep result\n",
    "            preds_list.extend(list(np.array(torch.max(predictions, 1)[1].numpy(), dtype=int)))\n",
    "            label_list.extend(list(np.array(batch.priority.numpy(), dtype=int)))\n",
    "\n",
    "            # compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.priority.long())\n",
    "            \n",
    "            # train loss.\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), preds_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_vocab = len(TEXT.vocab)\n",
    "\n",
    "\n",
    "def SGD(tr_x, val_x, n_epoches=100, lr = 0.001, dropout = 0.3, batch_size = 32, num_hidden_nodes = 32):\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    \n",
    "    embedding_dim = 300\n",
    "    num_output_nodes = 5\n",
    "    num_layers = 1 # depth\n",
    "    bidirection = True\n",
    "    \n",
    "    # GPU or CPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "    \n",
    "    # Load an iterator\n",
    "    train_iterator, valid_iterator = data.BucketIterator.splits((tr_x, val_x), \n",
    "                                                                batch_size = batch_size,\n",
    "                                                                sort_key = lambda x: len(x.content),\n",
    "                                                                sort_within_batch=True,\n",
    "                                                                device=device)\n",
    "\n",
    "\n",
    "\n",
    "    # model print(model)\n",
    "    model = RNN_classifier(size_of_vocab, embedding_dim, \n",
    "                       num_hidden_nodes,num_output_nodes, \n",
    "                       num_layers, bidirectional = True, \n",
    "                       dropout = dropout)\n",
    "    \n",
    "    # pre-trained Glove.\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    \n",
    "    # define optimizer and loss.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-8)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # training\n",
    "    for epoch in range(n_epoches):\n",
    "\n",
    "        #train the model\n",
    "        train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "\n",
    "        #evaluate the model\n",
    "        valid_loss, preds_list, label_list = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        \n",
    "        print(f\"Epoch: {epoch:d} : Train Loss: {train_loss:.4f} | Valid loss: {valid_loss:.4f}\")\n",
    "        \n",
    "        if (len(valid_loss_list) >= 2):\n",
    "            if (valid_loss_list[-2] - valid_loss_list[-1]) < 0.0001: break\n",
    "        \n",
    "    return train_loss_list, valid_loss_list, preds_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper-parameter choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for hn in [10, 20, 40, 100]:\n",
    "#     for lr in [0.001, 0.01, 0.1]:\n",
    "#         print(\"hidden layer nodes: \", hn, \", learning rate: \", lr)\n",
    "#         train_loss, valid_loss = SGD(tr_x, val_x, \n",
    "#                                      n_epoches=50, lr=lr, \n",
    "#                                      dropout=0, batch_size = 64, \n",
    "#                                      num_hidden_nodes = hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 : Train Loss: 1.6052 | Valid loss: 1.6026\n",
      "Epoch: 1 : Train Loss: 1.6002 | Valid loss: 1.5977\n",
      "Epoch: 2 : Train Loss: 1.5953 | Valid loss: 1.5929\n",
      "Epoch: 3 : Train Loss: 1.5905 | Valid loss: 1.5881\n",
      "Epoch: 4 : Train Loss: 1.5858 | Valid loss: 1.5835\n",
      "Epoch: 5 : Train Loss: 1.5811 | Valid loss: 1.5789\n",
      "Epoch: 6 : Train Loss: 1.5766 | Valid loss: 1.5745\n",
      "Epoch: 7 : Train Loss: 1.5721 | Valid loss: 1.5701\n",
      "Epoch: 8 : Train Loss: 1.5678 | Valid loss: 1.5658\n",
      "Epoch: 9 : Train Loss: 1.5634 | Valid loss: 1.5615\n",
      "Epoch: 10 : Train Loss: 1.5592 | Valid loss: 1.5574\n",
      "Epoch: 11 : Train Loss: 1.5551 | Valid loss: 1.5533\n",
      "Epoch: 12 : Train Loss: 1.5510 | Valid loss: 1.5493\n",
      "Epoch: 13 : Train Loss: 1.5470 | Valid loss: 1.5454\n",
      "Epoch: 14 : Train Loss: 1.5431 | Valid loss: 1.5416\n",
      "Epoch: 15 : Train Loss: 1.5393 | Valid loss: 1.5378\n",
      "Epoch: 16 : Train Loss: 1.5355 | Valid loss: 1.5342\n",
      "Epoch: 17 : Train Loss: 1.5319 | Valid loss: 1.5306\n",
      "Epoch: 18 : Train Loss: 1.5283 | Valid loss: 1.5272\n",
      "Epoch: 19 : Train Loss: 1.5249 | Valid loss: 1.5238\n",
      "Epoch: 20 : Train Loss: 1.5215 | Valid loss: 1.5205\n",
      "Epoch: 21 : Train Loss: 1.5182 | Valid loss: 1.5173\n",
      "Epoch: 22 : Train Loss: 1.5150 | Valid loss: 1.5142\n",
      "Epoch: 23 : Train Loss: 1.5119 | Valid loss: 1.5113\n",
      "Epoch: 24 : Train Loss: 1.5089 | Valid loss: 1.5084\n",
      "Epoch: 25 : Train Loss: 1.5061 | Valid loss: 1.5056\n",
      "Epoch: 26 : Train Loss: 1.5033 | Valid loss: 1.5030\n",
      "Epoch: 27 : Train Loss: 1.5007 | Valid loss: 1.5005\n",
      "Epoch: 28 : Train Loss: 1.4982 | Valid loss: 1.4981\n",
      "Epoch: 29 : Train Loss: 1.4958 | Valid loss: 1.4958\n",
      "Epoch: 30 : Train Loss: 1.4935 | Valid loss: 1.4936\n",
      "Epoch: 31 : Train Loss: 1.4913 | Valid loss: 1.4915\n",
      "Epoch: 32 : Train Loss: 1.4893 | Valid loss: 1.4896\n",
      "Epoch: 33 : Train Loss: 1.4873 | Valid loss: 1.4877\n",
      "Epoch: 34 : Train Loss: 1.4855 | Valid loss: 1.4860\n",
      "Epoch: 35 : Train Loss: 1.4837 | Valid loss: 1.4844\n",
      "Epoch: 36 : Train Loss: 1.4822 | Valid loss: 1.4828\n",
      "Epoch: 37 : Train Loss: 1.4806 | Valid loss: 1.4814\n",
      "Epoch: 38 : Train Loss: 1.4792 | Valid loss: 1.4801\n",
      "Epoch: 39 : Train Loss: 1.4779 | Valid loss: 1.4788\n",
      "Epoch: 40 : Train Loss: 1.4767 | Valid loss: 1.4777\n",
      "Epoch: 41 : Train Loss: 1.4755 | Valid loss: 1.4766\n",
      "Epoch: 42 : Train Loss: 1.4744 | Valid loss: 1.4755\n",
      "Epoch: 43 : Train Loss: 1.4734 | Valid loss: 1.4746\n",
      "Epoch: 44 : Train Loss: 1.4724 | Valid loss: 1.4737\n",
      "Epoch: 45 : Train Loss: 1.4716 | Valid loss: 1.4728\n",
      "Epoch: 46 : Train Loss: 1.4706 | Valid loss: 1.4720\n",
      "Epoch: 47 : Train Loss: 1.4699 | Valid loss: 1.4712\n",
      "Epoch: 48 : Train Loss: 1.4690 | Valid loss: 1.4705\n",
      "Epoch: 49 : Train Loss: 1.4684 | Valid loss: 1.4698\n",
      "Epoch: 50 : Train Loss: 1.4677 | Valid loss: 1.4692\n",
      "Epoch: 51 : Train Loss: 1.4671 | Valid loss: 1.4686\n",
      "Epoch: 52 : Train Loss: 1.4664 | Valid loss: 1.4680\n",
      "Epoch: 53 : Train Loss: 1.4658 | Valid loss: 1.4674\n",
      "Epoch: 54 : Train Loss: 1.4653 | Valid loss: 1.4669\n",
      "Epoch: 55 : Train Loss: 1.4648 | Valid loss: 1.4664\n",
      "Epoch: 56 : Train Loss: 1.4642 | Valid loss: 1.4659\n",
      "Epoch: 57 : Train Loss: 1.4637 | Valid loss: 1.4654\n",
      "Epoch: 58 : Train Loss: 1.4633 | Valid loss: 1.4649\n",
      "Epoch: 59 : Train Loss: 1.4628 | Valid loss: 1.4645\n",
      "Epoch: 60 : Train Loss: 1.4624 | Valid loss: 1.4640\n",
      "Epoch: 61 : Train Loss: 1.4620 | Valid loss: 1.4636\n",
      "Epoch: 62 : Train Loss: 1.4615 | Valid loss: 1.4632\n",
      "Epoch: 63 : Train Loss: 1.4612 | Valid loss: 1.4628\n",
      "Epoch: 64 : Train Loss: 1.4607 | Valid loss: 1.4625\n",
      "Epoch: 65 : Train Loss: 1.4604 | Valid loss: 1.4621\n",
      "Epoch: 66 : Train Loss: 1.4600 | Valid loss: 1.4617\n",
      "Epoch: 67 : Train Loss: 1.4596 | Valid loss: 1.4614\n",
      "Epoch: 68 : Train Loss: 1.4594 | Valid loss: 1.4610\n",
      "Epoch: 69 : Train Loss: 1.4590 | Valid loss: 1.4607\n",
      "Epoch: 70 : Train Loss: 1.4587 | Valid loss: 1.4604\n",
      "Epoch: 71 : Train Loss: 1.4583 | Valid loss: 1.4601\n",
      "Epoch: 72 : Train Loss: 1.4580 | Valid loss: 1.4597\n",
      "Epoch: 73 : Train Loss: 1.4577 | Valid loss: 1.4594\n",
      "Epoch: 74 : Train Loss: 1.4575 | Valid loss: 1.4592\n",
      "Epoch: 75 : Train Loss: 1.4572 | Valid loss: 1.4589\n",
      "Epoch: 76 : Train Loss: 1.4569 | Valid loss: 1.4586\n",
      "Epoch: 77 : Train Loss: 1.4565 | Valid loss: 1.4583\n",
      "Epoch: 78 : Train Loss: 1.4563 | Valid loss: 1.4580\n",
      "Epoch: 79 : Train Loss: 1.4560 | Valid loss: 1.4578\n",
      "Epoch: 80 : Train Loss: 1.4558 | Valid loss: 1.4575\n",
      "Epoch: 81 : Train Loss: 1.4555 | Valid loss: 1.4572\n",
      "Epoch: 82 : Train Loss: 1.4552 | Valid loss: 1.4570\n",
      "Epoch: 83 : Train Loss: 1.4550 | Valid loss: 1.4567\n",
      "Epoch: 84 : Train Loss: 1.4548 | Valid loss: 1.4565\n",
      "Epoch: 85 : Train Loss: 1.4545 | Valid loss: 1.4563\n",
      "Epoch: 86 : Train Loss: 1.4542 | Valid loss: 1.4560\n",
      "Epoch: 87 : Train Loss: 1.4541 | Valid loss: 1.4558\n",
      "Epoch: 88 : Train Loss: 1.4538 | Valid loss: 1.4556\n",
      "Epoch: 89 : Train Loss: 1.4536 | Valid loss: 1.4553\n",
      "Epoch: 90 : Train Loss: 1.4533 | Valid loss: 1.4551\n",
      "Epoch: 91 : Train Loss: 1.4531 | Valid loss: 1.4549\n",
      "Epoch: 92 : Train Loss: 1.4529 | Valid loss: 1.4547\n",
      "Epoch: 93 : Train Loss: 1.4527 | Valid loss: 1.4545\n",
      "Epoch: 94 : Train Loss: 1.4525 | Valid loss: 1.4543\n",
      "Epoch: 95 : Train Loss: 1.4522 | Valid loss: 1.4541\n",
      "Epoch: 96 : Train Loss: 1.4521 | Valid loss: 1.4539\n",
      "Epoch: 97 : Train Loss: 1.4519 | Valid loss: 1.4537\n",
      "Epoch: 98 : Train Loss: 1.4517 | Valid loss: 1.4535\n",
      "Epoch: 99 : Train Loss: 1.4514 | Valid loss: 1.4533\n",
      "Epoch: 100 : Train Loss: 1.4513 | Valid loss: 1.4531\n",
      "Epoch: 101 : Train Loss: 1.4510 | Valid loss: 1.4529\n",
      "Epoch: 102 : Train Loss: 1.4509 | Valid loss: 1.4527\n",
      "Epoch: 103 : Train Loss: 1.4506 | Valid loss: 1.4525\n",
      "Epoch: 104 : Train Loss: 1.4504 | Valid loss: 1.4523\n",
      "Epoch: 105 : Train Loss: 1.4503 | Valid loss: 1.4521\n",
      "Epoch: 106 : Train Loss: 1.4500 | Valid loss: 1.4519\n",
      "Epoch: 107 : Train Loss: 1.4499 | Valid loss: 1.4517\n",
      "Epoch: 108 : Train Loss: 1.4496 | Valid loss: 1.4515\n",
      "Epoch: 109 : Train Loss: 1.4495 | Valid loss: 1.4514\n",
      "Epoch: 110 : Train Loss: 1.4493 | Valid loss: 1.4512\n",
      "Epoch: 111 : Train Loss: 1.4491 | Valid loss: 1.4510\n",
      "Epoch: 112 : Train Loss: 1.4489 | Valid loss: 1.4508\n",
      "Epoch: 113 : Train Loss: 1.4487 | Valid loss: 1.4506\n",
      "Epoch: 114 : Train Loss: 1.4485 | Valid loss: 1.4504\n",
      "Epoch: 115 : Train Loss: 1.4484 | Valid loss: 1.4503\n",
      "Epoch: 116 : Train Loss: 1.4482 | Valid loss: 1.4501\n",
      "Epoch: 117 : Train Loss: 1.4481 | Valid loss: 1.4499\n",
      "Epoch: 118 : Train Loss: 1.4479 | Valid loss: 1.4497\n",
      "Epoch: 119 : Train Loss: 1.4477 | Valid loss: 1.4496\n",
      "Epoch: 120 : Train Loss: 1.4475 | Valid loss: 1.4494\n",
      "Epoch: 121 : Train Loss: 1.4473 | Valid loss: 1.4492\n",
      "Epoch: 122 : Train Loss: 1.4471 | Valid loss: 1.4490\n",
      "Epoch: 123 : Train Loss: 1.4470 | Valid loss: 1.4488\n",
      "Epoch: 124 : Train Loss: 1.4467 | Valid loss: 1.4487\n",
      "Epoch: 125 : Train Loss: 1.4466 | Valid loss: 1.4485\n",
      "Epoch: 126 : Train Loss: 1.4464 | Valid loss: 1.4483\n",
      "Epoch: 127 : Train Loss: 1.4462 | Valid loss: 1.4481\n",
      "Epoch: 128 : Train Loss: 1.4460 | Valid loss: 1.4479\n",
      "Epoch: 129 : Train Loss: 1.4459 | Valid loss: 1.4478\n",
      "Epoch: 130 : Train Loss: 1.4457 | Valid loss: 1.4476\n",
      "Epoch: 131 : Train Loss: 1.4455 | Valid loss: 1.4474\n",
      "Epoch: 132 : Train Loss: 1.4453 | Valid loss: 1.4472\n",
      "Epoch: 133 : Train Loss: 1.4450 | Valid loss: 1.4470\n",
      "Epoch: 134 : Train Loss: 1.4449 | Valid loss: 1.4469\n",
      "Epoch: 135 : Train Loss: 1.4447 | Valid loss: 1.4467\n",
      "Epoch: 136 : Train Loss: 1.4445 | Valid loss: 1.4465\n",
      "Epoch: 137 : Train Loss: 1.4443 | Valid loss: 1.4463\n",
      "Epoch: 138 : Train Loss: 1.4441 | Valid loss: 1.4461\n",
      "Epoch: 139 : Train Loss: 1.4439 | Valid loss: 1.4459\n",
      "Epoch: 140 : Train Loss: 1.4438 | Valid loss: 1.4457\n",
      "Epoch: 141 : Train Loss: 1.4435 | Valid loss: 1.4455\n",
      "Epoch: 142 : Train Loss: 1.4434 | Valid loss: 1.4454\n",
      "Epoch: 143 : Train Loss: 1.4432 | Valid loss: 1.4452\n",
      "Epoch: 144 : Train Loss: 1.4430 | Valid loss: 1.4450\n",
      "Epoch: 145 : Train Loss: 1.4428 | Valid loss: 1.4448\n",
      "Epoch: 146 : Train Loss: 1.4425 | Valid loss: 1.4446\n",
      "Epoch: 147 : Train Loss: 1.4424 | Valid loss: 1.4444\n",
      "Epoch: 148 : Train Loss: 1.4423 | Valid loss: 1.4442\n",
      "Epoch: 149 : Train Loss: 1.4420 | Valid loss: 1.4440\n",
      "Epoch: 150 : Train Loss: 1.4419 | Valid loss: 1.4438\n",
      "Epoch: 151 : Train Loss: 1.4416 | Valid loss: 1.4436\n",
      "Epoch: 152 : Train Loss: 1.4414 | Valid loss: 1.4434\n",
      "Epoch: 153 : Train Loss: 1.4411 | Valid loss: 1.4432\n",
      "Epoch: 154 : Train Loss: 1.4410 | Valid loss: 1.4430\n",
      "Epoch: 155 : Train Loss: 1.4407 | Valid loss: 1.4427\n",
      "Epoch: 156 : Train Loss: 1.4405 | Valid loss: 1.4425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157 : Train Loss: 1.4403 | Valid loss: 1.4423\n",
      "Epoch: 158 : Train Loss: 1.4401 | Valid loss: 1.4421\n",
      "Epoch: 159 : Train Loss: 1.4399 | Valid loss: 1.4419\n",
      "Epoch: 160 : Train Loss: 1.4397 | Valid loss: 1.4417\n",
      "Epoch: 161 : Train Loss: 1.4394 | Valid loss: 1.4415\n",
      "Epoch: 162 : Train Loss: 1.4392 | Valid loss: 1.4412\n",
      "Epoch: 163 : Train Loss: 1.4389 | Valid loss: 1.4410\n",
      "Epoch: 164 : Train Loss: 1.4387 | Valid loss: 1.4408\n",
      "Epoch: 165 : Train Loss: 1.4385 | Valid loss: 1.4406\n",
      "Epoch: 166 : Train Loss: 1.4382 | Valid loss: 1.4403\n",
      "Epoch: 167 : Train Loss: 1.4380 | Valid loss: 1.4401\n",
      "Epoch: 168 : Train Loss: 1.4377 | Valid loss: 1.4399\n",
      "Epoch: 169 : Train Loss: 1.4375 | Valid loss: 1.4396\n",
      "Epoch: 170 : Train Loss: 1.4373 | Valid loss: 1.4394\n",
      "Epoch: 171 : Train Loss: 1.4371 | Valid loss: 1.4391\n",
      "Epoch: 172 : Train Loss: 1.4367 | Valid loss: 1.4389\n",
      "Epoch: 173 : Train Loss: 1.4365 | Valid loss: 1.4387\n",
      "Epoch: 174 : Train Loss: 1.4363 | Valid loss: 1.4384\n",
      "Epoch: 175 : Train Loss: 1.4360 | Valid loss: 1.4382\n",
      "Epoch: 176 : Train Loss: 1.4357 | Valid loss: 1.4379\n",
      "Epoch: 177 : Train Loss: 1.4355 | Valid loss: 1.4377\n",
      "Epoch: 178 : Train Loss: 1.4353 | Valid loss: 1.4374\n",
      "Epoch: 179 : Train Loss: 1.4349 | Valid loss: 1.4371\n",
      "Epoch: 180 : Train Loss: 1.4347 | Valid loss: 1.4369\n",
      "Epoch: 181 : Train Loss: 1.4344 | Valid loss: 1.4366\n",
      "Epoch: 182 : Train Loss: 1.4341 | Valid loss: 1.4364\n",
      "Epoch: 183 : Train Loss: 1.4339 | Valid loss: 1.4361\n",
      "Epoch: 184 : Train Loss: 1.4336 | Valid loss: 1.4358\n",
      "Epoch: 185 : Train Loss: 1.4333 | Valid loss: 1.4356\n",
      "Epoch: 186 : Train Loss: 1.4331 | Valid loss: 1.4353\n",
      "Epoch: 187 : Train Loss: 1.4328 | Valid loss: 1.4350\n",
      "Epoch: 188 : Train Loss: 1.4325 | Valid loss: 1.4347\n",
      "Epoch: 189 : Train Loss: 1.4322 | Valid loss: 1.4345\n",
      "Epoch: 190 : Train Loss: 1.4319 | Valid loss: 1.4342\n",
      "Epoch: 191 : Train Loss: 1.4317 | Valid loss: 1.4339\n",
      "Epoch: 192 : Train Loss: 1.4313 | Valid loss: 1.4336\n",
      "Epoch: 193 : Train Loss: 1.4310 | Valid loss: 1.4333\n",
      "Epoch: 194 : Train Loss: 1.4308 | Valid loss: 1.4330\n",
      "Epoch: 195 : Train Loss: 1.4304 | Valid loss: 1.4328\n",
      "Epoch: 196 : Train Loss: 1.4301 | Valid loss: 1.4325\n",
      "Epoch: 197 : Train Loss: 1.4298 | Valid loss: 1.4322\n",
      "Epoch: 198 : Train Loss: 1.4295 | Valid loss: 1.4319\n",
      "Epoch: 199 : Train Loss: 1.4293 | Valid loss: 1.4316\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss, preds_list, label_list = SGD(tr_X, te_X, \n",
    "                             n_epoches=200, \n",
    "                             lr=0.001, \n",
    "                             dropout=0, \n",
    "                             batch_size = 64, \n",
    "                             num_hidden_nodes = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = [i for i in range(len(train_loss))]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epoch, train_loss)\n",
    "plt.plot(epoch, valid_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4579045837231057\n",
      "Precision: 0.30107724331273\n",
      "Recall: 0.3847558563621491\n",
      "F1-Score: 0.3272409860480403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y_te = label_list\n",
    "preds_te = preds_list\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_te,preds_te))\n",
    "print('Precision:', precision_score(Y_te,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(Y_te,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_te,preds_te,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
