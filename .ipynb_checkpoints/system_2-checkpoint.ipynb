{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-class tweets classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pytorch - LSTM introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/pytorch_LSTM_1.png\" width=\"550\">\n",
    "\n",
    "### 1.1 LSTM architecture\n",
    "> **model = nn.LSTM(input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional)**\n",
    "1. input_size: 每个单词的 embedding or one-hot encoding 的尺寸，例如：glove 300d。\n",
    "2. hidden_size: 隐含层神经元的个数，例如上图的n。\n",
    "3. num_layers: LSTM的层数，例如上图的层数为1。\n",
    "4. bias: default true。\n",
    "5. batch_first: \n",
    "6. dropout: 0-1\n",
    "7. bidirectional: true or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 100])\n",
      "torch.Size([12, 3])\n",
      "torch.Size([12])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "lstm = nn.LSTM(100, 3, 2)  # word embedding size is 300, hidden layer size is 3, two LSTM layer. \n",
    "print(lstm.all_weights[0][0].shape)\n",
    "print(lstm.all_weights[0][1].shape)\n",
    "print(lstm.all_weights[0][2].shape)\n",
    "print(lstm.all_weights[0][3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 LSTM input and output\n",
    "><img src=\"image/pytorch_LSTM.png\" width=\"500\">\n",
    ">\n",
    ">**output, ($\\text{h}_n$, $\\text{c}_n$) = model(input, ($\\text{h}_0$, $\\text{c}_0$))**\n",
    ">\n",
    ">* input维度：(句子长度, batch_size（一次多少个句子）, input_size（每个单词向量的长度）) 。\n",
    ">* $\\text{h}_0, \\text{c}_0$维度：(num_layers * num_directions, batch, hidden_size)。例如，上图有w+1层，单向，hidden_size为每个LSTM结构内隐含层神经元个数。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. sentence length:  5  word embedding: torch.Size([1, 100])\n",
      "2. input is every word in sentence:  torch.Size([1, 1, 100])\n",
      "3. output size:  torch.Size([1, 1, 3])\n",
      "4. h_1 size:  torch.Size([2, 1, 3])\n",
      "5. c_1 size:  torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = [torch.randn(1, 100) for _ in range(5)] # In a sentence, 5 words, every words' length is 4.\n",
    "\n",
    "hidden = (torch.randn(2*1, 1, 3), torch.randn(2*1, 1, 3)) # h_0, c_0.\n",
    "\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "print(\"1. sentence length: \",len(inputs),\" word embedding:\",inputs[0].shape)\n",
    "print(\"2. input is every word in sentence: \", i.view(1, 1, -1).shape)\n",
    "print(\"3. output size: \", out.shape)\n",
    "print(\"4. h_1 size: \", hidden[0].shape)\n",
    "print(\"5. c_1 size: \", hidden[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 forward pass\n",
    ">**module(data) = module.forward(data)**\n",
    ">\n",
    "><img src=\"image/forward.png\" width=\"550\">\n",
    "\n",
    "### 1.4 handle input with variable length\n",
    ">* torch.nn.utils.rnn.pad_sequence()：把不等长的tensor数据, 补充成等长的tensor数据.\n",
    "* torch.nn.utils.rnn.pack_padded_sequence()：把等长的tensor根据所输入的参数压缩成实际的数据, 同时数据格式变成PackedSequence。\n",
    "* torch.nn.utils.rnn.pad_packed_sequence()：把上面所压缩成PackedSequence的数据还原成tensor类型, 并补成等长的数据。\n",
    "\n",
    "https://blog.csdn.net/kejizuiqianfang/article/details/100835528\n",
    "\n",
    "### 1.5 pytorch loss function for classification\n",
    ">\n",
    ">* nn.Softmax and nn.LogSoftmax: \n",
    "* nn.NLLLoss: negative log likelihood loss. \n",
    "* nn.CrossEntropy: the combination of nn.Softmax and nn.NLLLoss.\n",
    "* nn.BCELoss: *bianry* classification loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. bi-directional GRU for priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-processed dataset.\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch   \n",
    "from torchtext import data \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import os\n",
    "from torchtext.vocab import Vectors\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 dataset processing in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"pre-processed data/new_label_testset.csv\")[['priority', 'content']]\n",
    "dataset = pd.read_csv(\"pre-processed data/new_label_dataset.csv\")[['priority', 'content']]\n",
    "\n",
    "dataset = dataset[dataset['priority'] != 'Unknown']\n",
    "\n",
    "testset.to_csv(\"pre-processed data/testset_priority.csv\", index=False)\n",
    "dataset.to_csv(\"pre-processed data/dataset_priority.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priority': 'Low', 'content': ['philippine', 'flood', 'worsen', 'death', 'toll', 'hit', 'wake', 'gener']}\n",
      "{'priority': 'High', 'content': ['view', 'shell', 'gregoire']}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2020)\n",
    "\n",
    "# loading custom dataset\n",
    "TEXT = data.Field(tokenize=lambda x: x.split() ,batch_first=True, include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float, batch_first=True)\n",
    "\n",
    "fields = [('priority', LABEL), ('content', TEXT)]\n",
    "\n",
    "dataset, testset = data.TabularDataset.splits(\n",
    "    path = 'pre-processed data/',\n",
    "    train = 'dataset_priority.csv',\n",
    "    test = 'testset_priority.csv',\n",
    "    format = 'csv',\n",
    "    fields = fields,\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(vars(dataset.examples[0]))\n",
    "print(vars(testset.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 6392\n",
      "Size of LABEL vocabulary: 4\n",
      "Top words:  [('earthquake', 2846), ('school', 2577), ('shoot', 2453), ('nepal', 2414), ('philippine', 2358)]\n",
      "LABEL vocabulary:  defaultdict(None, {'Low': 0, 'Medium': 1, 'High': 2, 'Critical': 3})\n"
     ]
    }
   ],
   "source": [
    "# load downloaded glove word embedding.\n",
    "cache = '.vector_cache'\n",
    "if not os.path.exists(cache): os.mkdir(cache)\n",
    "vectors = Vectors(name='./glove.840B.300d.txt', cache=cache)\n",
    "\n",
    "# create vocab.\n",
    "TEXT.build_vocab(dataset, min_freq=3, vectors=vectors)\n",
    "LABEL.build_vocab(dataset)\n",
    "\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "print(\"Top words: \", TEXT.vocab.freqs.most_common(5))  \n",
    "\n",
    "# Word dictionary.\n",
    "print(\"LABEL vocabulary: \", LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_classifier(nn.Module):\n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # bi-directional LSTM\n",
    "        self.lstm = nn.GRU(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers=n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "\n",
    "        # dense layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, 128)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "        \n",
    "        # don't need activation function if using nn.CrossEntropy\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        # text word index.\n",
    "        embedded = self.embedding(text) # shape = [batch, length, word embedding]\n",
    "        \n",
    "        # packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "\n",
    "        packed_output, hidden = self.lstm(packed_embedded) # GRU has two outputs, LSTM has three. eg. packed_output, (hidden, cell)\n",
    "        \n",
    "        # hidden shape [2, 64, num_hidden_nodes] if LSTM shape [1, 64, num_hidden_nodes]\n",
    "        # concat the final forward and backward hidden state (use hidden state, not output)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        hidden_outputs = self.fc(hidden)\n",
    "        \n",
    "        outputs1 = self.fc1(F.relu(hidden_outputs)) # F.log_softmax()\n",
    "        \n",
    "        outputs2 = self.fc2(F.relu(outputs1))\n",
    "        \n",
    "        return outputs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 training and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #retrieve text and no. of words\n",
    "        cont, cont_lengths = batch.content \n",
    "\n",
    "        # forward\n",
    "        predictions = model(cont, cont_lengths).squeeze()  \n",
    "\n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, batch.priority.long())  \n",
    "        \n",
    "        # backward\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step() \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()     \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    label_list, preds_list, prob_list = [], [], []\n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    # deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            \n",
    "            # retrieve text and length\n",
    "            cont, cont_lengths = batch.content \n",
    "\n",
    "            predictions = model(cont, cont_lengths).squeeze()\n",
    "            \n",
    "            # keep result\n",
    "            preds_list.extend(list(np.array(torch.max(predictions, 1)[1].numpy(), dtype=int)))\n",
    "            label_list.extend(list(np.array(batch.priority.numpy(), dtype=int)))\n",
    "            prob_list.extend(F.softmax(predictions).numpy())\n",
    "\n",
    "            # compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.priority.long())\n",
    "            \n",
    "            # train loss.\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), preds_list, label_list, prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_vocab = len(TEXT.vocab)\n",
    "\n",
    "\n",
    "def SGD(tr_x, val_x, n_epoches=100, lr = 0.001, dropout = 0.3, batch_size = 32, num_hidden_nodes = 32):\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    \n",
    "    embedding_dim = 300\n",
    "    num_output_nodes = 4\n",
    "    num_layers = 1 # depth\n",
    "    bidirection = True\n",
    "    \n",
    "    # GPU or CPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "    \n",
    "    # Load an iterator\n",
    "    train_iterator, valid_iterator = data.BucketIterator.splits((tr_x, val_x), \n",
    "                                                                batch_size = batch_size,\n",
    "                                                                sort_key = lambda x: len(x.content),\n",
    "                                                                sort_within_batch=True,\n",
    "                                                                device=device)\n",
    "\n",
    "\n",
    "    \n",
    "    # model print(model)\n",
    "    model = RNN_classifier(size_of_vocab, embedding_dim, \n",
    "                       num_hidden_nodes,num_output_nodes, \n",
    "                       num_layers, bidirectional = True, \n",
    "                       dropout = dropout)\n",
    "    \n",
    "    # pre-trained Glove.\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    \n",
    "    # define optimizer and loss.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-8)\n",
    "    criterion = nn.CrossEntropyLoss() # nn.NLLLoss()\n",
    "    \n",
    "    # training\n",
    "    for epoch in range(n_epoches):\n",
    "\n",
    "        #train the model\n",
    "        train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "\n",
    "        #evaluate the model\n",
    "        valid_loss, preds_list, label_list, prob_list = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        \n",
    "        print(f\"Epoch: {epoch:d} : Train Loss: {train_loss:.4f} | Valid loss: {valid_loss:.4f}\")\n",
    "        \n",
    "        if len(valid_loss_list) > 2:\n",
    "            if (valid_loss_list[-2] - valid_loss_list[-1])<0.0001 and (valid_loss_list[-2] - valid_loss_list[-1])>0:\n",
    "                break\n",
    "        \n",
    "    return train_loss_list, valid_loss_list, preds_list, label_list, prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hyper-parameter choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 : Train Loss: 1.3260 | Valid loss: 1.2179\n",
      "Epoch: 1 : Train Loss: 1.2112 | Valid loss: 1.0703\n",
      "Epoch: 2 : Train Loss: 1.1203 | Valid loss: 0.9415\n",
      "Epoch: 3 : Train Loss: 1.0454 | Valid loss: 0.8267\n",
      "Epoch: 4 : Train Loss: 0.9866 | Valid loss: 0.7320\n",
      "Epoch: 5 : Train Loss: 0.9464 | Valid loss: 0.6641\n",
      "Epoch: 6 : Train Loss: 0.9229 | Valid loss: 0.6225\n",
      "Epoch: 7 : Train Loss: 0.9096 | Valid loss: 0.5991\n",
      "Epoch: 8 : Train Loss: 0.9013 | Valid loss: 0.5857\n",
      "Epoch: 9 : Train Loss: 0.8952 | Valid loss: 0.5792\n",
      "Epoch: 10 : Train Loss: 0.8904 | Valid loss: 0.5755\n",
      "Epoch: 11 : Train Loss: 0.8863 | Valid loss: 0.5731\n",
      "Epoch: 12 : Train Loss: 0.8828 | Valid loss: 0.5720\n",
      "Epoch: 13 : Train Loss: 0.8797 | Valid loss: 0.5716\n",
      "Epoch: 14 : Train Loss: 0.8771 | Valid loss: 0.5713\n",
      "Epoch: 15 : Train Loss: 0.8747 | Valid loss: 0.5698\n",
      "Epoch: 16 : Train Loss: 0.8726 | Valid loss: 0.5696\n",
      "Epoch: 17 : Train Loss: 0.8708 | Valid loss: 0.5700\n",
      "Epoch: 18 : Train Loss: 0.8690 | Valid loss: 0.5695\n",
      "Epoch: 19 : Train Loss: 0.8674 | Valid loss: 0.5683\n",
      "Epoch: 20 : Train Loss: 0.8660 | Valid loss: 0.5678\n",
      "Epoch: 21 : Train Loss: 0.8646 | Valid loss: 0.5682\n",
      "Epoch: 22 : Train Loss: 0.8633 | Valid loss: 0.5684\n",
      "Epoch: 23 : Train Loss: 0.8621 | Valid loss: 0.5671\n",
      "Epoch: 24 : Train Loss: 0.8609 | Valid loss: 0.5665\n",
      "Epoch: 25 : Train Loss: 0.8597 | Valid loss: 0.5658\n",
      "Epoch: 26 : Train Loss: 0.8587 | Valid loss: 0.5663\n",
      "Epoch: 27 : Train Loss: 0.8576 | Valid loss: 0.5660\n",
      "Epoch: 28 : Train Loss: 0.8565 | Valid loss: 0.5647\n",
      "Epoch: 29 : Train Loss: 0.8554 | Valid loss: 0.5647\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss, preds_list, label_list, prob_list = SGD(dataset, testset, \n",
    "                             n_epoches=200, \n",
    "                             lr=0.0008, \n",
    "                             dropout=0.2, \n",
    "                             batch_size = 64, \n",
    "                             num_hidden_nodes = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE all:  0.04767058948532197\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "score = 0\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    index = label_list[i]\n",
    "    if index == 0: weight = 0.25\n",
    "    elif index == 1: weight = 0.5\n",
    "    elif index == 2: weight = 0.75\n",
    "    elif index == 3: weight = 1\n",
    "    else: weight = 0\n",
    "    score += (weight - weight*prob_list[i][index])**2\n",
    "    \n",
    "print(\"RMSE all: \", score/len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = [i for i in range(len(train_loss))]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epoch, train_loss)\n",
    "plt.plot(epoch, valid_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8770020784937034\n",
      "Precision: 0.21925051962342584\n",
      "Recall: 0.25\n",
      "F1-Score: 0.233617769671704\n"
     ]
    }
   ],
   "source": [
    "Y_te = label_list\n",
    "preds_te = preds_list\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_te,preds_te))\n",
    "print('Precision:', precision_score(Y_te,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(Y_te,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_te,preds_te,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    ">1. choose SGD rather than Adam.\n",
    ">2. using nn.CrossEntropyLoss() (nn.logSoftmax() + nn.NLLLoss()) for multi-class classification.\n",
    "\n",
    "tutorial: https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
